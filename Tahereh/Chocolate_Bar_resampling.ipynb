{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd9dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb7504",
   "metadata": {},
   "source": [
    "# Read the clean_flavors_of_cacao.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b2512b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Bean_Origin_or_Bar_Name</th>\n",
       "      <th>REF</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Cocoa_Percent</th>\n",
       "      <th>Company_Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean_Type</th>\n",
       "      <th>Broad_Bean_Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>missing</td>\n",
       "      <td>Sao Tome &amp; Principe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>missing</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company Bean_Origin_or_Bar_Name   REF  Review_Date  Cocoa_Percent  \\\n",
       "0  A. Morin             Agua Grande  1876         2016           63.0   \n",
       "1  A. Morin                   Kpime  1676         2015           70.0   \n",
       "2  A. Morin                  Atsane  1676         2015           70.0   \n",
       "3  A. Morin                   Akata  1680         2015           70.0   \n",
       "4  A. Morin                  Quilla  1704         2015           70.0   \n",
       "\n",
       "  Company_Location  Rating Bean_Type    Broad_Bean_Origin  \n",
       "0           France    3.75   missing  Sao Tome & Principe  \n",
       "1           France    2.75   missing                 Togo  \n",
       "2           France    3.00   missing                 Togo  \n",
       "3           France    3.50   missing                 Togo  \n",
       "4           France    3.50   missing                 Peru  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('clean_flavors_of_cacao.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d55b6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Cocoa_Percent</th>\n",
       "      <th>Company_Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean_Type</th>\n",
       "      <th>Broad_Bean_Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>missing</td>\n",
       "      <td>Sao Tome &amp; Principe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>missing</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company  Review_Date  Cocoa_Percent Company_Location  Rating Bean_Type  \\\n",
       "0  A. Morin         2016           63.0           France    3.75   missing   \n",
       "1  A. Morin         2015           70.0           France    2.75   missing   \n",
       "2  A. Morin         2015           70.0           France    3.00   missing   \n",
       "3  A. Morin         2015           70.0           France    3.50   missing   \n",
       "4  A. Morin         2015           70.0           France    3.50   missing   \n",
       "\n",
       "     Broad_Bean_Origin  \n",
       "0  Sao Tome & Principe  \n",
       "1                 Togo  \n",
       "2                 Togo  \n",
       "3                 Togo  \n",
       "4                 Peru  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop(columns=[\"REF\",\"Bean_Origin_or_Bar_Name\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebfc1107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.18676552881925"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466f3196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47757934371049987"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3814e076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1cb26a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1787.000000\n",
       "mean        3.186766\n",
       "std         0.477579\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         3.250000\n",
       "75%         3.500000\n",
       "max         5.000000\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20e276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_ratings(rating):\n",
    "    if rating == 5.75: return 1\n",
    "    if rating == 5.50: return 1\n",
    "    if rating == 5.25: return 1\n",
    "    if rating == 5.00: return 1\n",
    "    \n",
    "    if rating == 4.75: return 1\n",
    "    if rating == 4.50: return 1\n",
    "    if rating == 4.25: return 1\n",
    "    if rating == 4.00: return 1\n",
    "    \n",
    "    if rating == 3.75: return 1\n",
    "    if rating == 3.50: return 0\n",
    "    if rating == 3.25: return 0\n",
    "    if rating == 3.00: return 0\n",
    "\n",
    "    if rating == 2.75: return 0\n",
    "    if rating == 2.50: return 0\n",
    "    if rating == 2.25: return 0\n",
    "    if rating == 2.00: return 0\n",
    "    \n",
    "    if rating == 1.75: return 0\n",
    "    if rating == 1.50: return 0\n",
    "    if rating == 1.25: return 0\n",
    "    if rating == 1.00: return 0\n",
    "    \n",
    "    #print( f\"error: rating={rating} type={type(rating)}\" )\n",
    "    return \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4204ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'] = df['Rating'].apply(bin_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fbec7c",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "577a025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Rating\"]\n",
    "X = df.drop(columns=\"Rating\")\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "523d0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "   y,test_size= 0.3,train_size=0.7 , random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eabd2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d1210",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "962374f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1035, 1: 1035})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Random Oversampling\n",
    "\n",
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Instantiate the model\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "# Resample the targets\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0747789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Calculate predictions\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e1ccf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6794536471955828"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6986858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>336</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>37</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                  336                 108\n",
       "Actual low_risk                    37                  56"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e65b69da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.76      0.60      0.82      0.68      0.46       444\n",
      "          1       0.34      0.60      0.76      0.44      0.68      0.45        93\n",
      "\n",
      "avg / total       0.80      0.73      0.63      0.76      0.68      0.46       537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1938b130",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9924429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 215, 1: 215})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "# Instantiate\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf37aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "901003ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.519180470793374"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95c0b8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>60</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                   60                 384\n",
       "Actual low_risk                     9                  84"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff1bd7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.87      0.14      0.90      0.23      0.35      0.11       444\n",
      "          1       0.18      0.90      0.14      0.30      0.35      0.13        93\n",
      "\n",
      "avg / total       0.75      0.27      0.77      0.25      0.35      0.12       537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a557572d",
   "metadata": {},
   "source": [
    "# Combination (Over and Under) Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18f4793d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 592, 1: 1382})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f668a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tata\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d29d6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.608435047951177"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a6b08b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>187</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>19</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                  187                 257\n",
       "Actual low_risk                    19                  74"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23269e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.91      0.42      0.80      0.58      0.58      0.32       444\n",
      "          1       0.22      0.80      0.42      0.35      0.58      0.35        93\n",
      "\n",
      "avg / total       0.79      0.49      0.73      0.54      0.58      0.33       537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b6498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

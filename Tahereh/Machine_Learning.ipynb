{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import plotly as pl \n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Bean_Origin_or_Bar_Name</th>\n",
       "      <th>REF</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Cocoa_Percent</th>\n",
       "      <th>Company_Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean_Type</th>\n",
       "      <th>Broad_Bean_Origin</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Most_Memorable_Characteristics</th>\n",
       "      <th>country_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>missing</td>\n",
       "      <td>Sao Tome &amp; Principe</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>sweet, chocolatey, vegetal</td>\n",
       "      <td>ST</td>\n",
       "      <td>0.186360</td>\n",
       "      <td>6.613081</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>burnt wood, earthy, choco</td>\n",
       "      <td>TG</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>roasty, acidic, nutty</td>\n",
       "      <td>TG</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>mild profile, chocolaty, spice</td>\n",
       "      <td>TG</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>missing</td>\n",
       "      <td>Peru</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>grainy texture, cocoa, sweet</td>\n",
       "      <td>PE</td>\n",
       "      <td>-9.189967</td>\n",
       "      <td>-75.015152</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company Bean_Origin_or_Bar_Name   REF  Review_Date  Cocoa_Percent  \\\n",
       "0  A. Morin             Agua Grande  1876         2016           63.0   \n",
       "1  A. Morin                   Kpime  1676         2015           70.0   \n",
       "2  A. Morin                  Atsane  1676         2015           70.0   \n",
       "3  A. Morin                   Akata  1680         2015           70.0   \n",
       "4  A. Morin                  Quilla  1704         2015           70.0   \n",
       "\n",
       "  Company_Location  Rating Bean_Type    Broad_Bean_Origin Ingredients  \\\n",
       "0           France    3.75   missing  Sao Tome & Principe  4- B,S,C,L   \n",
       "1           France    2.75   missing                 Togo  4- B,S,C,L   \n",
       "2           France    3.00   missing                 Togo  4- B,S,C,L   \n",
       "3           France    3.50   missing                 Togo  4- B,S,C,L   \n",
       "4           France    3.50   missing                 Peru  4- B,S,C,L   \n",
       "\n",
       "   Most_Memorable_Characteristics country_code  latitude  longitude  \\\n",
       "0      sweet, chocolatey, vegetal           ST  0.186360   6.613081   \n",
       "1       burnt wood, earthy, choco           TG  8.619543   0.824782   \n",
       "2           roasty, acidic, nutty           TG  8.619543   0.824782   \n",
       "3  mild profile, chocolaty, spice           TG  8.619543   0.824782   \n",
       "4    grainy texture, cocoa, sweet           PE -9.189967 -75.015152   \n",
       "\n",
       "       continent  \n",
       "0         Africa  \n",
       "1         Africa  \n",
       "2         Africa  \n",
       "3         Africa  \n",
       "4  South America  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chocolate = pd.read_csv(\"clean_flavors_of_cacao.csv\", encoding='utf-8')\n",
    "df_chocolate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_ratings(rating):\n",
    "    if rating == 5.75: return 1\n",
    "    if rating == 5.50: return 1\n",
    "    if rating == 5.25: return 1\n",
    "    if rating == 5.00: return 1\n",
    "    \n",
    "    if rating == 4.75: return 1\n",
    "    if rating == 4.50: return 1\n",
    "    if rating == 4.25: return 1\n",
    "    if rating == 4.00: return 1\n",
    "    \n",
    "    if rating == 3.75: return 1\n",
    "    if rating == 3.50: return 0\n",
    "    if rating == 3.25: return 0\n",
    "    if rating == 3.00: return 0\n",
    "\n",
    "    if rating == 2.75: return 0\n",
    "    if rating == 2.50: return 0\n",
    "    if rating == 2.25: return 0\n",
    "    if rating == 2.00: return 0\n",
    "    \n",
    "    if rating == 1.75: return 0\n",
    "    if rating == 1.50: return 0\n",
    "    if rating == 1.25: return 0\n",
    "    if rating == 1.00: return 0\n",
    "    \n",
    "    #print( f\"error: rating={rating} type={type(rating)}\" )\n",
    "    return \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chocolate['Rating'] = df_chocolate['Rating'].apply(bin_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(value):\n",
    "    other = f\"_{value}_\"\n",
    "    return other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_count_vals(df, colname, threshold):\n",
    "    counts = df[colname].value_counts()\n",
    "    replace_list = list(counts[counts < threshold].index)\n",
    "\n",
    "    # Replace in dataframe\n",
    "    for item in replace_list:\n",
    "       df[colname] = df[colname].replace(item,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chocolate['Review_Date']= df_chocolate['Review_Date'].apply(to_string)\n",
    "reduce_count_vals(df_chocolate, 'Review_Date', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Cocoa_Percent</th>\n",
       "      <th>Company_Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean_Type</th>\n",
       "      <th>Broad_Bean_Origin</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>country_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_2016_</td>\n",
       "      <td>63.0</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>Sao Tome &amp; Principe</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>ST</td>\n",
       "      <td>0.186360</td>\n",
       "      <td>6.613081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_2015_</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>TG</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_2015_</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>TG</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_2015_</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>missing</td>\n",
       "      <td>Togo</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>TG</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_2015_</td>\n",
       "      <td>70.0</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>missing</td>\n",
       "      <td>Peru</td>\n",
       "      <td>4- B,S,C,L</td>\n",
       "      <td>PE</td>\n",
       "      <td>-9.189967</td>\n",
       "      <td>-75.015152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Review_Date  Cocoa_Percent Company_Location  Rating Bean_Type  \\\n",
       "0      _2016_           63.0           France       1   missing   \n",
       "1      _2015_           70.0           France       0   missing   \n",
       "2      _2015_           70.0           France       0   missing   \n",
       "3      _2015_           70.0           France       0   missing   \n",
       "4      _2015_           70.0           France       0   missing   \n",
       "\n",
       "     Broad_Bean_Origin Ingredients country_code  latitude  longitude  \n",
       "0  Sao Tome & Principe  4- B,S,C,L           ST  0.186360   6.613081  \n",
       "1                 Togo  4- B,S,C,L           TG  8.619543   0.824782  \n",
       "2                 Togo  4- B,S,C,L           TG  8.619543   0.824782  \n",
       "3                 Togo  4- B,S,C,L           TG  8.619543   0.824782  \n",
       "4                 Peru  4- B,S,C,L           PE -9.189967 -75.015152  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "df_chocolate= df_chocolate.drop(columns=[\"Company\",\"REF\",\"Bean_Origin_or_Bar_Name\",\"Most_Memorable_Characteristics\",\"continent\"], axis=1)\n",
    "df_chocolate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Review_Date',\n",
       " 'Company_Location',\n",
       " 'Bean_Type',\n",
       " 'Broad_Bean_Origin',\n",
       " 'Ingredients',\n",
       " 'country_code']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists\n",
    "chocolate_cat = df_chocolate.dtypes[df_chocolate.dtypes == 'object'].index.tolist()\n",
    "chocolate_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Date_Other</th>\n",
       "      <th>Review_Date__2008_</th>\n",
       "      <th>Review_Date__2009_</th>\n",
       "      <th>Review_Date__2010_</th>\n",
       "      <th>Review_Date__2011_</th>\n",
       "      <th>Review_Date__2012_</th>\n",
       "      <th>Review_Date__2013_</th>\n",
       "      <th>Review_Date__2014_</th>\n",
       "      <th>Review_Date__2015_</th>\n",
       "      <th>Review_Date__2016_</th>\n",
       "      <th>...</th>\n",
       "      <th>country_code_TG</th>\n",
       "      <th>country_code_TT</th>\n",
       "      <th>country_code_TZ</th>\n",
       "      <th>country_code_UG</th>\n",
       "      <th>country_code_US</th>\n",
       "      <th>country_code_VE</th>\n",
       "      <th>country_code_VN</th>\n",
       "      <th>country_code_VU</th>\n",
       "      <th>country_code_WS</th>\n",
       "      <th>country_code_ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_Date_Other  Review_Date__2008_  Review_Date__2009_  \\\n",
       "0                0.0                 0.0                 0.0   \n",
       "1                0.0                 0.0                 0.0   \n",
       "2                0.0                 0.0                 0.0   \n",
       "3                0.0                 0.0                 0.0   \n",
       "4                0.0                 0.0                 0.0   \n",
       "\n",
       "   Review_Date__2010_  Review_Date__2011_  Review_Date__2012_  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   Review_Date__2013_  Review_Date__2014_  Review_Date__2015_  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 1.0   \n",
       "2                 0.0                 0.0                 1.0   \n",
       "3                 0.0                 0.0                 1.0   \n",
       "4                 0.0                 0.0                 1.0   \n",
       "\n",
       "   Review_Date__2016_  ...  country_code_TG  country_code_TT  country_code_TZ  \\\n",
       "0                 1.0  ...              0.0              0.0              0.0   \n",
       "1                 0.0  ...              1.0              0.0              0.0   \n",
       "2                 0.0  ...              1.0              0.0              0.0   \n",
       "3                 0.0  ...              1.0              0.0              0.0   \n",
       "4                 0.0  ...              0.0              0.0              0.0   \n",
       "\n",
       "   country_code_UG  country_code_US  country_code_VE  country_code_VN  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   country_code_VU  country_code_WS  country_code_ZZ  \n",
       "0              0.0              0.0              0.0  \n",
       "1              0.0              0.0              0.0  \n",
       "2              0.0              0.0              0.0  \n",
       "3              0.0              0.0              0.0  \n",
       "4              0.0              0.0              0.0  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_chocolate[chocolate_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(chocolate_cat)\n",
    "encode_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cocoa_Percent</th>\n",
       "      <th>Rating</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Review_Date_Other</th>\n",
       "      <th>Review_Date__2008_</th>\n",
       "      <th>Review_Date__2009_</th>\n",
       "      <th>Review_Date__2010_</th>\n",
       "      <th>Review_Date__2011_</th>\n",
       "      <th>Review_Date__2012_</th>\n",
       "      <th>...</th>\n",
       "      <th>country_code_TG</th>\n",
       "      <th>country_code_TT</th>\n",
       "      <th>country_code_TZ</th>\n",
       "      <th>country_code_UG</th>\n",
       "      <th>country_code_US</th>\n",
       "      <th>country_code_VE</th>\n",
       "      <th>country_code_VN</th>\n",
       "      <th>country_code_VU</th>\n",
       "      <th>country_code_WS</th>\n",
       "      <th>country_code_ZZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186360</td>\n",
       "      <td>6.613081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.619543</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.189967</td>\n",
       "      <td>-75.015152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cocoa_Percent  Rating  latitude  longitude  Review_Date_Other  \\\n",
       "0           63.0       1  0.186360   6.613081                0.0   \n",
       "1           70.0       0  8.619543   0.824782                0.0   \n",
       "2           70.0       0  8.619543   0.824782                0.0   \n",
       "3           70.0       0  8.619543   0.824782                0.0   \n",
       "4           70.0       0 -9.189967 -75.015152                0.0   \n",
       "\n",
       "   Review_Date__2008_  Review_Date__2009_  Review_Date__2010_  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   Review_Date__2011_  Review_Date__2012_  ...  country_code_TG  \\\n",
       "0                 0.0                 0.0  ...              0.0   \n",
       "1                 0.0                 0.0  ...              1.0   \n",
       "2                 0.0                 0.0  ...              1.0   \n",
       "3                 0.0                 0.0  ...              1.0   \n",
       "4                 0.0                 0.0  ...              0.0   \n",
       "\n",
       "   country_code_TT  country_code_TZ  country_code_UG  country_code_US  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   country_code_VE  country_code_VN  country_code_VU  country_code_WS  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   country_code_ZZ  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 213 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "df_chocolate = df_chocolate.merge(encode_df, left_index=True, right_index=True).drop(chocolate_cat, 1)\n",
    "df_chocolate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_chocolate[\"Rating\"]\n",
    "X = df_chocolate.drop([\"Rating\"],1) \n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "   y,test_size= 0.4,train_size=0.6 , random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584183673469388"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>593</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                  593                  61\n",
       "Actual low_risk                    50                  80"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       654\n",
      "           1       0.57      0.62      0.59       130\n",
      "\n",
      "    accuracy                           0.86       784\n",
      "   macro avg       0.74      0.76      0.75       784\n",
      "weighted avg       0.86      0.86      0.86       784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance in the Random Forest model.\n",
    "importances = rf_model.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16540078518706983, 'Cocoa_Percent'),\n",
       " (0.04174798784110652, 'Company_Location_United States of America'),\n",
       " (0.04041893382681975, 'longitude'),\n",
       " (0.03660528105632691, 'latitude'),\n",
       " (0.030921519355748772, 'Ingredients_3- B,S,C'),\n",
       " (0.029452602187631124, 'Bean_Type_missing'),\n",
       " (0.02920731998234425, 'Review_Date__2015_'),\n",
       " (0.02741009667245025, 'Review_Date__2009_'),\n",
       " (0.0267180245741858, 'Ingredients_2- B,S'),\n",
       " (0.02508045461026639, 'Review_Date__2014_'),\n",
       " (0.023034308109295444, 'Review_Date__2016_'),\n",
       " (0.02110416772881794, 'Company_Location_Canada'),\n",
       " (0.019283740393615457, 'Ingredients_Unknown'),\n",
       " (0.019075205979600055, 'Ingredients_4- B,S,C,V'),\n",
       " (0.0186392376562422, 'Review_Date__2012_'),\n",
       " (0.01855931109842744, 'Review_Date__2013_'),\n",
       " (0.01639805106976491, 'Review_Date__2011_'),\n",
       " (0.015411730899734525, 'Review_Date_Other'),\n",
       " (0.01461879561666939, 'Ingredients_5- B,S,C,V,L'),\n",
       " (0.014326245474192879, 'Bean_Type_Trinitario'),\n",
       " (0.014032325717544213, 'Ingredients_4- B,S,C,L'),\n",
       " (0.013488013300249922, 'Company_Location_Ecuador'),\n",
       " (0.01341694481965955, 'Bean_Type_Criollo'),\n",
       " (0.012601425995350687, 'Company_Location_France'),\n",
       " (0.012333597853311973, 'Company_Location_England'),\n",
       " (0.0120890173257375, 'Review_Date__2010_'),\n",
       " (0.011606624838294846, 'Bean_Type_Forastero'),\n",
       " (0.008424767558349013, 'country_code_VE'),\n",
       " (0.00821463187371507, 'Broad_Bean_Origin_Venezuela'),\n",
       " (0.008053644801581595, 'Review_Date__2008_'),\n",
       " (0.007194550361486743, 'Company_Location_Australia'),\n",
       " (0.006942943363254007, 'Company_Location_Italy'),\n",
       " (0.006659283362903016, 'country_code_PE'),\n",
       " (0.00657591583094233, 'country_code_EC'),\n",
       " (0.006541159708017928, 'Broad_Bean_Origin_Peru'),\n",
       " (0.006537997036400101, 'Company_Location_Peru'),\n",
       " (0.006143672683184, 'Broad_Bean_Origin_Ecuador'),\n",
       " (0.005327512364965361, 'Broad_Bean_Origin_Dominican Republic'),\n",
       " (0.005318727596942701, 'Broad_Bean_Origin_Madagascar'),\n",
       " (0.005075019084947118, 'Company_Location_Madagascar'),\n",
       " (0.004900696732059819, 'country_code_DO'),\n",
       " (0.004867624063946295, 'country_code_MG'),\n",
       " (0.004749177671101999, 'country_code_ZZ'),\n",
       " (0.004443790873209647, 'Company_Location_Germany'),\n",
       " (0.004321322710922994, 'Company_Location_Hungary'),\n",
       " (0.004274848351068547, 'Broad_Bean_Origin_Unknown'),\n",
       " (0.004271100721231224, 'Company_Location_Colombia'),\n",
       " (0.004081043392555402, 'Broad_Bean_Origin_Grenada'),\n",
       " (0.003912811056757512, 'country_code_BR'),\n",
       " (0.003886006995745731, 'country_code_NI'),\n",
       " (0.003876614556951399, 'country_code_GD'),\n",
       " (0.0038735221209406532, 'Company_Location_Spain'),\n",
       " (0.003854556618604795, 'Company_Location_Switzerland'),\n",
       " (0.0038281252664528515, 'Broad_Bean_Origin_Nicaragua'),\n",
       " (0.003818914114869208, 'Company_Location_Brazil'),\n",
       " (0.0037113693048930778, 'Bean_Type_Blend'),\n",
       " (0.0035763791430954064, 'Broad_Bean_Origin_Brazil'),\n",
       " (0.003427649047558355, 'Broad_Bean_Origin_Tanzania'),\n",
       " (0.0033700978401411254, 'Company_Location_Belgium'),\n",
       " (0.003076858732533839, 'country_code_TZ'),\n",
       " (0.002997861533434816, 'Broad_Bean_Origin_Colombia'),\n",
       " (0.002905390051826066, 'country_code_CO'),\n",
       " (0.0027274759771633034, 'Broad_Bean_Origin_Mexico'),\n",
       " (0.002696477534935295, 'country_code_MX'),\n",
       " (0.002668829289226318, 'country_code_CR'),\n",
       " (0.002536161718216347, 'Company_Location_Denmark'),\n",
       " (0.0025323081698059254, 'Company_Location_Austria'),\n",
       " (0.0024626876075427074, 'Company_Location_Venezuela'),\n",
       " (0.0024311643577274796, 'Broad_Bean_Origin_Costa Rica'),\n",
       " (0.0022737606568135923, 'country_code_US'),\n",
       " (0.0021375426469069166, 'country_code_GT'),\n",
       " (0.0021129245483515993, 'Broad_Bean_Origin_Belize'),\n",
       " (0.0020500916649718206, 'Broad_Bean_Origin_Other'),\n",
       " (0.0020194980736020296, 'country_code_VN'),\n",
       " (0.0020153359984808814, 'Broad_Bean_Origin_Fiji'),\n",
       " (0.0019329086973437911, 'country_code_TT'),\n",
       " (0.0019327452435174985, 'Broad_Bean_Origin_Jamaica'),\n",
       " (0.0019156430338794232, 'Broad_Bean_Origin_United States'),\n",
       " (0.0019008114689514693, 'Broad_Bean_Origin_Vietnam'),\n",
       " (0.0018993410425387788, 'Broad_Bean_Origin_Guatemala'),\n",
       " (0.0018825929630897945, 'Broad_Bean_Origin_Trinidad Tobago'),\n",
       " (0.0018399759717555022, 'Company_Location_Lithuania'),\n",
       " (0.0017634583949363793, 'Company_Location_Scotland'),\n",
       " (0.001761176976752395, 'country_code_BZ'),\n",
       " (0.001727617017673023, 'Broad_Bean_Origin_Papua New Guinea'),\n",
       " (0.0017218678532478554, 'Company_Location_Vietnam'),\n",
       " (0.001703809143531689, 'country_code_JM'),\n",
       " (0.0015926398180400195, 'country_code_FJ'),\n",
       " (0.0015659331332604795, 'Company_Location_Ireland'),\n",
       " (0.0015432420013704524, 'country_code_PG'),\n",
       " (0.001526781795788934, 'Broad_Bean_Origin_Bolivia'),\n",
       " (0.0014756461794749236, 'Company_Location_Poland'),\n",
       " (0.0014687185455865745, 'country_code_GH'),\n",
       " (0.001402912438526875, 'Company_Location_Honduras'),\n",
       " (0.0013985320995265331, 'Broad_Bean_Origin_Ghana'),\n",
       " (0.0013275874887944614, 'Ingredients_4- B,Sw,C,Sa'),\n",
       " (0.0012867426066433347, 'Company_Location_Guatemala'),\n",
       " (0.0012549817722387485, 'country_code_BO'),\n",
       " (0.0011901429337616014, 'country_code_PA'),\n",
       " (0.0011411452580839109, 'Broad_Bean_Origin_Panama'),\n",
       " (0.0011398837261074979, 'country_code_UG'),\n",
       " (0.0011268620203004284, 'Broad_Bean_Origin_Uganda'),\n",
       " (0.0011087467301907925, 'Bean_Type_EET'),\n",
       " (0.0009486133621597217, 'country_code_CU'),\n",
       " (0.0009464600946135892, 'Company_Location_Chile'),\n",
       " (0.0009065204475285825, 'Company_Location_Japan'),\n",
       " (0.0009006347775580508, 'Broad_Bean_Origin_Cuba'),\n",
       " (0.0008872028151998943, 'country_code_ST'),\n",
       " (0.0008726200920089377, 'Broad_Bean_Origin_Sao Tome & Principe'),\n",
       " (0.0008462477736194192, 'Company_Location_New Zealand'),\n",
       " (0.0007987877815935581, 'Company_Location_Costa Rica'),\n",
       " (0.0007366419075734464, 'Company_Location_Fiji'),\n",
       " (0.0007308293600158224, 'Broad_Bean_Origin_Honduras'),\n",
       " (0.000727647681088197, 'Bean_Type_Beniano'),\n",
       " (0.0007223935441442931, 'Company_Location_Netherlands'),\n",
       " (0.000707790493853182, 'country_code_HN'),\n",
       " (0.0006211992786508982, 'Ingredients_2- B,Sw'),\n",
       " (0.000608228213645614, 'Ingredients_1- B'),\n",
       " (0.0005957649944252782, 'Bean_Type_Amazon mix'),\n",
       " (0.0005919688193698107, 'Company_Location_Nicaragua'),\n",
       " (0.00058829354144663, 'Bean_Type_Nacional (Arriba)'),\n",
       " (0.0005515607009164143, 'Bean_Type_Matina'),\n",
       " (0.00055080991088755, 'country_code_LK'),\n",
       " (0.0005476251984761003, 'Ingredients_4- B,Sw,C,L'),\n",
       " (0.000538315795693005, 'country_code_HT'),\n",
       " (0.000526068653143698, 'Broad_Bean_Origin_Haiti'),\n",
       " (0.0005087618093773641, 'Company_Location_Sweden'),\n",
       " (0.0005076492138914513, 'country_code_PH'),\n",
       " (0.000489340228394795, 'Broad_Bean_Origin_Philippines'),\n",
       " (0.0004634872518614485, 'country_code_LR'),\n",
       " (0.00046254015693768426, 'Company_Location_Singapore'),\n",
       " (0.0004585785961428625, 'Broad_Bean_Origin_India'),\n",
       " (0.00045636289355535534, 'Company_Location_Argentina'),\n",
       " (0.0004559353774836722, 'country_code_IN'),\n",
       " (0.0004285921458311219, 'Company_Location_Dominican Republic'),\n",
       " (0.00042496519982202776, 'Broad_Bean_Origin_Republic of Congo'),\n",
       " (0.00040115203627905956, 'Broad_Bean_Origin_Sri Lanka'),\n",
       " (0.0003809283070630793, 'Broad_Bean_Origin_Saint Lucia'),\n",
       " (0.00036447956655524816, 'country_code_SB'),\n",
       " (0.0003632648120386805, 'country_code_LC'),\n",
       " (0.00035026092858089834, 'country_code_CG'),\n",
       " (0.000349370510248311, 'Company_Location_Iceland'),\n",
       " (0.0003401209802862127, 'Company_Location_Sao Tome'),\n",
       " (0.00033964276311240847, 'Company_Location_Israel'),\n",
       " (0.00033386503868512946, 'Broad_Bean_Origin_Liberia'),\n",
       " (0.00032993693675418303, 'Company_Location_South Africa'),\n",
       " (0.0002839023108968649, 'Ingredients_4- B,S,C,Sa'),\n",
       " (0.00028299012767552895, 'Ingredients_3- B,Sw,C'),\n",
       " (0.00026056718309048766, 'country_code_WS'),\n",
       " (0.000260070514840435, 'country_code_CI'),\n",
       " (0.0002581623171860506, 'Broad_Bean_Origin_Solomon Islands'),\n",
       " (0.00025535047897595357, 'Broad_Bean_Origin_Puerto Rico'),\n",
       " (0.0002522169772241038, 'country_code_ID'),\n",
       " (0.00024883108285006327, 'Bean_Type_Amazon, ICS'),\n",
       " (0.00024198095713240912, 'Broad_Bean_Origin_Indonesia'),\n",
       " (0.00023453938574317365, 'country_code_PR'),\n",
       " (0.00023448340833322084, 'Ingredients_6-B,S,C,V,L,Sa'),\n",
       " (0.0002142053278587213, 'Broad_Bean_Origin_Samoa'),\n",
       " (0.00018499483492701399, 'Company_Location_Grenada'),\n",
       " (0.0001747338010929589, 'Company_Location_Bolivia'),\n",
       " (0.00017033049601940502, 'Ingredients_2- B,C'),\n",
       " (0.000166557846692896, 'Ingredients_3- B,S,L'),\n",
       " (0.00016443388882566171, \"Broad_Bean_Origin_Cote d'Ivorie\"),\n",
       " (0.0001340559890348061, 'Company_Location_St. Lucia'),\n",
       " (0.00013076018683995882, 'Company_Location_Mexico'),\n",
       " (0.00011783033715600066, 'Company_Location_Puerto Rico'),\n",
       " (9.913267058035151e-05, 'Company_Location_India'),\n",
       " (9.499740799365801e-05, 'Ingredients_4- B,Sw,C,V'),\n",
       " (7.390037480687614e-05, 'Company_Location_Philippines'),\n",
       " (7.381511927377579e-05, 'Ingredients_4- B,Sw,V,L'),\n",
       " (7.030846172865594e-05, 'Ingredients_4- B,S,V,L'),\n",
       " (6.60433120397739e-05, 'Broad_Bean_Origin_Vanuatu'),\n",
       " (6.474379282878567e-05, 'country_code_SV'),\n",
       " (6.0600208411474746e-05, 'Bean_Type_CCN51'),\n",
       " (5.293802094027269e-05, 'country_code_VU'),\n",
       " (5.2172769716461875e-05, 'Broad_Bean_Origin_El Salvador'),\n",
       " (4.825370313593278e-05, 'Broad_Bean_Origin_Martinique'),\n",
       " (4.0509945692805506e-05, 'Company_Location_Martinique'),\n",
       " (2.8432881627111778e-05, 'Company_Location_Wales'),\n",
       " (2.7652011573545665e-05, 'country_code_MQ'),\n",
       " (1.5810365953515486e-09, 'Broad_Bean_Origin_Australia'),\n",
       " (0.0, 'country_code_TG'),\n",
       " (0.0, 'country_code_SR'),\n",
       " (0.0, 'country_code_NG'),\n",
       " (0.0, 'country_code_MY'),\n",
       " (0.0, 'country_code_MM'),\n",
       " (0.0, 'country_code_GA'),\n",
       " (0.0, 'country_code_CM'),\n",
       " (0.0, 'country_code_AU'),\n",
       " (0.0, 'Ingredients_5-B,S,C,V,Sa'),\n",
       " (0.0, 'Ingredients_5- B,S,C,L,Sa'),\n",
       " (0.0, 'Ingredients_3- B,Sw,Sa'),\n",
       " (0.0, 'Ingredients_3- B,Sw+H108,C'),\n",
       " (0.0, 'Ingredients_3- B,S,V'),\n",
       " (0.0, 'Company_Location_Suriname'),\n",
       " (0.0, 'Company_Location_South Korea'),\n",
       " (0.0, 'Company_Location_Russia'),\n",
       " (0.0, 'Company_Location_Portugal'),\n",
       " (0.0, 'Company_Location_Ghana'),\n",
       " (0.0, 'Company_Location_Finland'),\n",
       " (0.0, 'Company_Location_Czech Republic'),\n",
       " (0.0, 'Broad_Bean_Origin_Togo'),\n",
       " (0.0, 'Broad_Bean_Origin_Suriname'),\n",
       " (0.0, 'Broad_Bean_Origin_Peru(SMartin,Pangoa,nacional)'),\n",
       " (0.0, 'Broad_Bean_Origin_Other(DR/Jam/Tri)'),\n",
       " (0.0, 'Broad_Bean_Origin_Nigeria'),\n",
       " (0.0, 'Broad_Bean_Origin_Myanmar'),\n",
       " (0.0, 'Broad_Bean_Origin_Malaysia'),\n",
       " (0.0, 'Broad_Bean_Origin_Gabon'),\n",
       " (0.0, 'Broad_Bean_Origin_Cameroon'),\n",
       " (0.0, 'Bean_Type_Nacional'),\n",
       " (0.0, 'Bean_Type_Amazon')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM model accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "# Create the SVM model\n",
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "print(f\" SVM model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380102040816326"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                  653                   1\n",
       "Actual low_risk                   126                   4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       654\n",
      "           1       0.80      0.03      0.06       130\n",
      "\n",
      "    accuracy                           0.84       784\n",
      "   macro avg       0.82      0.51      0.49       784\n",
      "weighted avg       0.83      0.84      0.77       784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               54528     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 98,465\n",
      "Trainable params: 98,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  256\n",
    "hidden_nodes_layer2 = 128\n",
    "hidden_nodes_layer3 = 64\n",
    "hidden_nodes_layer4 = 32\n",
    "hidden_nodes_layer5 = 16\n",
    "hidden_nodes_layer6 = 8\n",
    "hidden_nodes_layer7 = 4\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer1, input_dim = number_input_features, activation = 'relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer2, activation = 'relu'))\n",
    "\n",
    "# other hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer3, activation = 'relu'))\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer4, activation = 'relu'))\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer5, activation = 'relu'))\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer6, activation = 'relu'))\n",
    "nn.add(tf.keras.layers.Dense(units = hidden_nodes_layer7, activation = 'relu'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.8282\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8333\n",
      "\n",
      "Epoch 00005: saving model to checkpoints/weights.05.hdf5\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8410\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8741\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.8988\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9014\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9141\n",
      "\n",
      "Epoch 00010: saving model to checkpoints/weights.10.hdf5\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9192\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9337\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.94 - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9371\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9388\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9439\n",
      "\n",
      "Epoch 00015: saving model to checkpoints/weights.15.hdf5\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9549\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1171 - accuracy: 0.9558\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9490\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9481\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0971 - accuracy: 0.9566\n",
      "\n",
      "Epoch 00020: saving model to checkpoints/weights.20.hdf5\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9600\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9634\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9609\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9592\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9609\n",
      "\n",
      "Epoch 00025: saving model to checkpoints/weights.25.hdf5\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9668\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9677\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9651\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9685\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9702\n",
      "\n",
      "Epoch 00030: saving model to checkpoints/weights.30.hdf5\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9626\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9685\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9660\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9660\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9626\n",
      "\n",
      "Epoch 00035: saving model to checkpoints/weights.35.hdf5\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9694\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9711\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9719\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9685\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9592\n",
      "\n",
      "Epoch 00040: saving model to checkpoints/weights.40.hdf5\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9549\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9575: 0s - loss: 0.0910 - accuracy: 0.95\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9643\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9694\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9711\n",
      "\n",
      "Epoch 00045: saving model to checkpoints/weights.45.hdf5\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9719\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9728\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9711\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9753\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9719\n",
      "\n",
      "Epoch 00050: saving model to checkpoints/weights.50.hdf5\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9728\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9753\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9762\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9736\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9753\n",
      "\n",
      "Epoch 00055: saving model to checkpoints/weights.55.hdf5\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9711\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9753\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9753\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9762\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9677\n",
      "\n",
      "Epoch 00060: saving model to checkpoints/weights.60.hdf5\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9753\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9753\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9745\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9745\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9753\n",
      "\n",
      "Epoch 00065: saving model to checkpoints/weights.65.hdf5\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9668\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9668\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9473\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9558\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9600\n",
      "\n",
      "Epoch 00070: saving model to checkpoints/weights.70.hdf5\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9634\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9719\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9643\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9745\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9719\n",
      "\n",
      "Epoch 00075: saving model to checkpoints/weights.75.hdf5\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9694\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9711\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9685\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9787\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9728\n",
      "\n",
      "Epoch 00080: saving model to checkpoints/weights.80.hdf5\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9728\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9770\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9779\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9762\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9779\n",
      "\n",
      "Epoch 00085: saving model to checkpoints/weights.85.hdf5\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9753\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9753\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9753\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9753\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9745\n",
      "\n",
      "Epoch 00090: saving model to checkpoints/weights.90.hdf5\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9745\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9745\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9770\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9753\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9753\n",
      "\n",
      "Epoch 00095: saving model to checkpoints/weights.95.hdf5\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9753\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9779\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9762\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9753\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9762\n",
      "\n",
      "Epoch 00100: saving model to checkpoints/weights.100.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe955d1ed50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "nn.fit(X_train_scaled, y_train, epochs = 100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 2.8068 - accuracy: 0.7985\n",
      "Loss: 2.8067543506622314, Accuracy: 0.7984693646430969\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save(\"Chocolate_Ratings_ML.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
